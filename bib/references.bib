@article{angelopoulos2021gentle,
  abstract = {Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction (a.k.a. conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on. This hands-on introduction is aimed to provide the reader a working understanding of conformal prediction and related distribution-free uncertainty quantification techniques with one self-contained document. We lead the reader through practical theory for and examples of conformal prediction and describe its extensions to complex machine learning tasks involving structured outputs, distribution shift, time-series, outliers, models that abstain, and more. Throughout, there are many explanatory illustrations, examples, and code samples in Python. With each code sample comes a Jupyter notebook implementing the method on a real-data example; the notebooks can be accessed and easily run by clicking on the following icons:},
  address = {UC Berkeley, Berkeley, CA, USA},
  author = {Angelopoulos, Anastasios N and Bates, Stephen},
  doi = {10.48550/arXiv.2107.07511},
  issn = {null},
  journal = {ArXiv},
  keywords = {type:technique, scope:Conformal Prediction, category:survey, keywords:conformal prediction, keywords:distribution-free uncertainty quantification},
  number = {null},
  pages = {null},
  publisher = {arXiv},
  references = {null},
  series = {null},
  title = {A gentle introduction to conformal prediction and distribution-free uncertainty quantification},
  volume = {abs/2107.07511},
  year = {2021},
  url = {https://arxiv.org/abs/2107.07511}
}
@article{berg2017graph,
  abstract = {We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.},
  address = {University of Amsterdam, Amsterdam, The Netherlands},
  author = {Berg, Rianne van den and Kipf, Thomas N and Welling, Max},
  doi = {10.48550/arXiv.1706.02263},
  issn = {null},
  journal = {ArXiv},
  keywords = {type:technique, scope:Inductive Matrix Completion, category:Graph Neural Networks, keywords:Graph neural networks, keywords:Matrix Completion, keywords:collaborative filtering},
  number = {null},
  pages = {null},
  publisher = {arXiv},
  references = {null},
  series = {null},
  title = {Graph convolutional matrix completion},
  volume = {abs/1706.02263},
  year = {2017},
  url = {https://arxiv.org/abs/1706.02263}
}
@article{chen2019inference,
  abstract = {Noisy matrix completion aims at estimating a low-rank matrix given only partial and corrupted entries. Despite remarkable progress in designing efficient estimation algorithms, it remains largely unclear how to assess the uncertainty of the obtained estimates and how to perform efficient statistical inference on the unknown matrix (e.g., constructing a valid and short confidence interval for an unseen entry). This paper takes a substantial step toward addressing such tasks. We develop a simple procedure to compensate for the bias of the widely used convex and nonconvex estimators. The resulting debiased estimators admit nearly precise nonasymptotic distributional characterizations, which in turn enable optimal construction of confidence intervals/regions for, say, the missing entries and the low-rank factors. Our inferential procedures do not require sample splitting, thus avoiding unnecessary loss of data efficiency. As a byproduct, we obtain a sharp characterization of the estimation accuracy of our debiased estimators in both rate and constant. Our debiased estimators are tractable algorithms that provably achieve full statistical efficiency.},
  address = {Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, USA},
  author = {Chen, Yuxin and Fan, Jianqing and Ma, Cong and Yan, Yuling},
  doi = {10.1073/pnas.1910053116},
  issn = {0027-8424},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {type:evaluation, scope:Matrix Completion, category:Statistically optimal inference and uncertainty quantification, keywords:conÔ¨Ådence intervals, keywords:convex relaxation, keywords:nonconvex optimization},
  number = {46},
  pages = {22931--22937},
  publisher = {National Academy of Sciences},
  references = {null},
  series = {null},
  title = {Inference and uncertainty quantification for noisy matrix completion},
  volume = {116},
  year = {2019},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.1910053116}
}
@article{gui2023conformalized,
  abstract = {Matrix completion aims to estimate missing entries in a data matrix, using the assumption of a low-complexity structure (e.g., low rank) so that imputation is possible. While many effective estimation algorithms exist in the literature, uncertainty quantification for this problem has proved to be challenging, and existing methods are extremely sensitive to model misspecification. In this work, we propose a distribution-free method for predictive inference in the matrix completion problem. Our method adapts the framework of conformal prediction, which provides confidence intervals with guaranteed distribution-free validity in the setting of regression, to the problem of matrix completion. Our resulting method, conformalized matrix completion (cmc), offers provable predictive coverage regardless of the accuracy of the low-rank model. Empirical results on simulated and real data demonstrate that cmc is robust to model misspecification while matching the performance of existing model-based methods when the model is correct.},
  address = {Department of Statistics, University of Chicago, Chicago, IL 60637, USA},
  arxivid = {2305.10637},
  author = {Gui, Yu and Barber, Rina and Ma, Cong},
  doi = {10.48550/arXiv.2305.10637},
  issn = {1049-5258},
  journal = {Advances in Neural Information Processing Systems},
  keywords = {type:technique, scope:Combination of Conformal Prediction and Inductive Matrix Completion, category:/, keywords:convex relaxation, keywords:rank, keywords:parameters, keywords:inference, keywords:norm},
  number = {null},
  pages = {4820--4844},
  publisher = {Neural Information Processing Systems (NIPS)},
  references = {null},
  series = {Advances in Neural Information Processing Systems},
  title = {Conformalized matrix completion},
  volume = {36},
  year = {2023},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/0f7e4bb7a35dd4cb426203c91a4bfa10-Abstract-Conference.html}
}
@article{jain2013provable,
  abstract = {Consider a movie recommendation system where apart from the ratings information, side information such as user's age or movie's genre is also available. Unlike standard matrix completion, in this setting one should be able to predict inductively on new users/movies. In this paper, we study the problem of inductive matrix completion in the exact recovery setting. That is, we assume that the ratings matrix is generated by applying feature vectors to a low-rank matrix and the goal is to recover back the underlying matrix. Furthermore, we generalize the problem to that of low-rank matrix estimation using rank-1 measurements. We study this generic problem and provide conditions that the set of measurements should satisfy so that the alternating minimization method (which otherwise is a non-convex method with no convergence guarantees) is able to recover back the exact underlying low-rank matrix. In addition to inductive matrix completion, we show that two other low-rank estimation problems can be studied in our framework: a) general low-rank matrix sensing using rank-1 measurements, and b) multi-label regression with missing labels. For both the problems, we provide novel and interesting bounds on the number of measurements required by alternating minimization to provably converges to the exact low-rank matrix. In particular, our analysis for the general low rank matrix sensing problem significantly improves the required storage and computational cost than that required by the RIP-based matrix sensing methods [1]. Finally, we provide empirical validation of our approach and demonstrate that alternating minimization is able to recover the true matrix for the above mentioned problems using a small number of measurements.},
  address = {Microsoft Research India, Bangalore, India},
  arxivid = {1306.0626},
  author = {Jain, Prateek and Dhillon, Inderjit S},
  doi = {10.48550/arXiv.1306.0626},
  issn = {null},
  journal = {ArXiv},
  keywords = {type:technique, scope:Inductive Matrix Completion, category:Standard Inductive Matrix Completion, keywords:Inductive Matrix Completion, keywords:alternating minimization, keywords:Low-Rank matrix estimation using Rank One Measurements, keywords:multi-label regression},
  number = {null},
  pages = {null},
  publisher = {arXiv},
  references = {null},
  series = {null},
  title = {Provable inductive matrix completion},
  volume = {abs/1306.0626},
  year = {2013},
  url = {https://arxiv.org/abs/1306.0626}
}
@article{monti2017geometric,
  abstract = {Matrix completion models are among the most common formulations of recommender systems. Recent works have showed a boost of performance of these techniques when introducing the pairwise relationships between users/items in the form of graphs, and imposing smoothness priors on these graphs. However, such techniques do not fully exploit the local stationarity structures of user/item graphs, and the number of parameters to learn is linear w.r.t. the number of users and items. We propose a novel approach to overcome these limitations by using geometric deep learning on graphs. Our matrix completion architecture combines graph convolutional neural networks and recurrent neural networks to learn meaningful statistical graph-structured patterns and the non-linear diffusion process that generates the known ratings. This neural network system requires a constant number of parameters independent of the matrix size. We apply our method on both synthetic and real datasets, showing that it outperforms state-of-the-art techniques.},
  address = {Universit√† della Svizzera italiana, Lugano, Switzerland},
  author = {Monti, Federico and Bronstein, Michael and Bresson, Xavier},
  doi = {10.48550/arXiv.1704.06803},
  issn = {1049-5258},
  journal = {Advances in Neural Information Processing Systems},
  keywords = {type:technique, scope:Inductive Matrix Completion, category:Graph Neural Networks, keywords:Matrix Completion, keywords:Recurrent Neural Networks, keywords:Graph Convolutional Neural Networks},
  number = {null},
  pages = {null},
  publisher = {Curran Associates, Inc.},
  references = {null},
  series = {Advances in Neural Information Processing Systems},
  title = {Geometric matrix completion with recurrent multi-graph neural networks},
  volume = {30},
  year = {2017},
  url = {https://arxiv.org/abs/1704.06803}
}
@article{natarajan2014inductive,
  abstract = {Motivation: Most existing methods for predicting causal disease genes rely on specific type of evidence, and are therefore limited in terms of applicability. More often than not, the type of evidence available for diseases varies‚Äîfor example, we may know linked genes, keywords associated with the disease obtained by mining text, or co-occurrence of disease symptoms in patients. Similarly, the type of evidence available for genes varies‚Äîfor example, specific microarray probes convey information only for certain sets of genes. In this article, we apply a novel matrix-completion method called Inductive Matrix Completion to the problem of predicting gene-disease associations; it combines multiple types of evidence (features) for diseases and genes to learn latent factors that explain the observed gene‚Äìdisease associations. We construct features from different biological sources such as microarray expression data and disease-related textual data. A crucial advantage of the method is that it is inductive; it can be applied to diseases not seen at training time, unlike traditional matrix-completion approaches and network-based inference methods that are transductive. Results: Comparison with state-of-the-art methods on diseases from the Online Mendelian Inheritance in Man (OMIM) database shows that the proposed approach is substantially better‚Äîit has close to one-in-four chance of recovering a true association in the top 100 predictions, compared to the recently proposed Catapult method (second best) that has <15% chance. We demonstrate that the inductive method is particularly effective for a query disease with no previously known gene associations, and for predicting novel genes, i.e. genes that are previously not linked to diseases. Thus the method is capable of predicting novel genes even for well-characterized diseases. We also validate the novelty of predictions by evaluating the method on recently reported OMIM associations and on associations recently reported in the literature. Availability: Source code and datasets can be downloaded from http://bigdata.ices.utexas.edu/project/gene-disease.},
  address = {Department of Computer Science, University of Texas at Austin, Austin, TX 78712, USA},
  author = {Natarajan, Nagarajan and Dhillon, Inderjit S},
  doi = {10.1093/bioinformatics/btu269},
  issn = {1367-4803},
  journal = {Bioinformatics},
  keywords = {type:application, scope:Inductive Matrix Completion, category:Standard Inductive Matrix Completion, keywords:network, keywords:prioritization, keywords:annotation, keywords:phenotype, keywords:resource, keywords:features, keywords:walking},
  number = {12},
  pages = {i60--i68},
  publisher = {Oxford University Press},
  references = {null},
  series = {null},
  title = {Inductive matrix completion for predicting gene--disease associations},
  volume = {30},
  year = {2014},
  url = {https://academic.oup.com/bioinformatics/article/30/12/i60/385272}
}
@inproceedings{zaffran2023conformal,
  abstract = {Conformal prediction is a theoretically grounded framework for constructing predictive intervals. We study conformal prediction with missing values in the covariates - a setting that brings new challenges to uncertainty quantification. We first show that the marginal coverage guarantee of conformal prediction holds on imputed data for any missingness distribution and almost all imputation functions. However, we emphasize that the average coverage varies depending on the pattern of missing values: conformal methods tend to construct prediction intervals that under-cover the response conditionally to some missing patterns. This motivates our novel generalized conformalized quantile regression framework, missing data augmentation, which yields prediction intervals that are valid conditionally to the patterns of missing values, despite their exponential number. We then show that a universally consistent quantile regression algorithm trained on the imputed data is Bayes optimal for the pinball risk, thus achieving valid coverage conditionally to any given data point. Moreover, we examine the case of a linear model, which demonstrates the importance of our proposal in overcoming the heteroskedasticity induced by missing values. Using synthetic and data from critical care, we corroborate our theory and report improved performance of our methods.},
  address = {Honolulu, Hawaii, USA},
  arxivid = {2306.02732},
  author = {Zaffran, Margaux and Dieuleveut, Aymeric and Josse, Julie and Romano, Yaniv},
  booktitle = {International Conference on Machine Learning},
  doi = {10.48550/arXiv.2306.02732},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  issn = {2640-3498},
  journal = {International Conference on Machine Learning},
  keywords = {type:technique, scope:Conformal Prediction, category:Uncertainty Quantification, keywords:bands},
  number = {null},
  pages = {40578--40604},
  publisher = {PMLR},
  references = {null},
  series = {Proceedings of Machine Learning Research},
  title = {Conformal prediction with missing values},
  volume = {202},
  year = {2023},
  organization = {PMLR},
  url = {https://proceedings.mlr.press/v202/zaffran23a.html}
}
@article{zeng2019deep,
  abstract = {Accurate prioritization of potential disease genes is a fundamental challenge in biomedical research. Various algorithms have been developed to solve such problems. Inductive Matrix Completion (IMC) is one of the most reliable models for its well-established framework and its superior performance in predicting gene-disease associations. However, the IMC method does not hierarchically extract deep features, which might limit the quality of recovery. In this case, the architecture of deep learning, which obtains high-level representations and handles noises and outliers presented in large-scale biological datasets, is introduced into the side information of genes in our Deep Collaborative Filtering (DCF) model. Further, for lack of negative examples, we also exploit Positive-Unlabeled (PU) learning formulation to low-rank matrix completion. Our approach achieves substantially improved performance over other state-of-the-art methods on diseases from the Online Mendelian Inheritance in Man (OMIM) database. Our approach is 10 percent more efficient than standard IMC in detecting a true association, and significantly outperforms other alternatives in terms of the precision-recall metric at the top-k predictions. Moreover, we also validate the disease with no previously known gene associations and newly reported OMIM associations. The experimental results show that DCF is still satisfactory for ranking novel disease phenotypes as well as mining unexplored relationships. The source code and the data are available at https://github.com/xzenglab/DCF.},
  address = {Xiamen University, Department of Computer Science, Xiamen 361005, People's Republic of China},
  author = {Zeng, Xiangxiang and Lin, Yinglai and He, Yuying and L{\"u}, Linyuan and Min, Xiaoping and Rodr{\'i}guez-Pat{\'o}n, Alfonso},
  doi = {10.1109/TCBB.2019.2907536},
  issn = {1545-5963},
  journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  keywords = {type:technique, scope:Inductive Matrix Completion, category:Deep Learning Architectures, keywords:disease genes prediction, keywords:data integration, keywords:deep learning, keywords:PU learning, keywords:matrix completion},
  number = {5},
  pages = {1639--1647},
  publisher = {IEEE},
  references = {null},
  series = {null},
  title = {Deep collaborative filtering for prediction of disease genes},
  volume = {17},
  year = {2019},
  url = {https://ieeexplore.ieee.org/abstract/document/8674571}
}
@article{zhang2019inductive,
  abstract = {We propose an inductive matrix completion model without using side information. By factorizing the (rating) matrix into the product of low-dimensional latent embeddings of rows (users) and columns (items), a majority of existing matrix completion methods are transductive, since the learned embeddings cannot generalize to unseen rows/columns or to new matrices. To make matrix completion inductive, most previous works use content (side information), such as user's age or movie's genre, to make predictions. However, high-quality content is not always available, and can be hard to extract. Under the extreme setting where not any side information is available other than the matrix to complete, can we still learn an inductive matrix completion model? In this paper, we propose an Inductive Graph-based Matrix Completion (IGMC) model to address this problem. IGMC trains a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps these subgraphs to their corresponding ratings. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive -- it can generalize to users/items unseen during the training (given that their interactions exist), and can even transfer to new tasks. Our transfer learning experiments show that a model trained out of the MovieLens dataset can be directly used to predict Douban movie ratings with surprisingly good performance. Our work demonstrates that: 1) it is possible to train inductive matrix completion models without using side information while achieving similar or better performances than state-of-the-art transductive methods; 2) local graph patterns around a (user, item) pair are effective predictors of the rating this user gives to the item; and 3) Long-range dependencies might not be necessary for modeling recommender systems.},
  address = {Washington University in St. Louis, St. Louis, MO 63130, USA},
  arxivid = {1904.12058},
  author = {Zhang, Muhan and Chen, Yixin},
  doi = {10.48550/arXiv.1904.12058},
  issn = {null},
  journal = {ArXiv},
  keywords = {type:technique, scope:Inductive Matrix Completion, category:Graph Neural Networks, keywords:Inductive Matrix Completion, keywords:Graph Neural Networks, keywords:side information, keywords:transfer learning},
  number = {null},
  pages = {null},
  publisher = {arXiv},
  references = {null},
  series = {null},
  title = {Inductive matrix completion based on graph neural networks},
  volume = {abs/1904.12058},
  year = {2019},
  url = {https://arxiv.org/abs/1904.12058}
}